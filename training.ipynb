{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.4)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (8.1.7)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (4.9.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (8.1.7)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.1.35-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m622.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (4.9.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.1.35-py3-none-any.whl (723 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.1/723.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.1.7\n",
      "    Uninstalling ultralytics-8.1.7:\n",
      "      Successfully uninstalled ultralytics-8.1.7\n",
      "Successfully installed ultralytics-8.1.35\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.35 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.7 🚀 Python-3.10.13 torch-2.1.2 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/divakar/Desktop/Yolotrain/poaching/data.yaml, epochs=10, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/divakar/Desktop/Yolotrain/poaching/train/labels... 777 images, 0 backgrounds, 0 corrupt: 100%|██████████| 777/777 [00:00<00:00, 3129.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/divakar/Desktop/Yolotrain/poaching/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/divakar/Desktop/Yolotrain/poaching/valid/labels... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<00:00, 3488.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/divakar/Desktop/Yolotrain/poaching/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train8\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G       1.86      3.205      1.937         33        640: 100%|██████████| 49/49 [05:41<00:00,  6.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.867      0.113      0.198     0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.555      2.116      1.681         26        640: 100%|██████████| 49/49 [06:36<00:00,  8.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80       0.76      0.366      0.391      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.473      1.835      1.617         34        640: 100%|██████████| 49/49 [07:39<00:00,  9.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.783      0.445       0.42      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.387      1.665      1.533         29        640: 100%|██████████| 49/49 [08:51<00:00, 10.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.838      0.445      0.487      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.314       1.51      1.464         26        640: 100%|██████████| 49/49 [08:43<00:00, 10.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.839      0.423      0.475      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.257      1.394      1.427         18        640: 100%|██████████| 49/49 [07:48<00:00,  9.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.914      0.447      0.517      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.205      1.288       1.38         31        640: 100%|██████████| 49/49 [07:59<00:00,  9.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.812      0.496      0.509      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      1.158      1.213      1.358         29        640: 100%|██████████| 49/49 [07:44<00:00,  9.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.899      0.505      0.537      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      1.126      1.172      1.329         36        640: 100%|██████████| 49/49 [10:13<00:00, 12.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.904      0.486      0.528      0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.078      1.106      1.305         33        640: 100%|██████████| 49/49 [11:54<00:00, 14.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27         80      0.948      0.504      0.543      0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 1.412 hours.\n",
      "Optimizer stripped from runs/detect/train8/weights/last.pt, 6.3MB\n",
      "Optimizer stripped from runs/detect/train8/weights/best.pt, 6.3MB\n",
      "\n",
      "Validating runs/detect/train8/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.7 🚀 Python-3.10.13 torch-2.1.2 CPU (Apple M1)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'WorldModel' from 'ultralytics.nn.tasks' (/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/nn/tasks.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/divakar/Desktop/Yolotrain/poaching/data.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/engine/model.py:391\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# embed second-to-last layer if no indices passed\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    387\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    388\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    389\u001b[0m     predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m--> 391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    392\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    Performs predictions on the given image source using the YOLO model.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m        AttributeError: If the predictor is not properly set up.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/engine/trainer.py:208\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/engine/trainer.py:465\u001b[0m, in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# must break all DDP ranks\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Do final val with best.pt\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs completed in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_time_start)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3600\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hours.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    470\u001b[0m     )\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_eval()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/engine/trainer.py:620\u001b[0m, in \u001b[0;36mfinal_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    617\u001b[0m     path \u001b[38;5;241m=\u001b[39m Path(name)\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplots[path] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m: time\u001b[38;5;241m.\u001b[39mtime()}\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinal_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Performs final evaluation and validation for object detection YOLO model.\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/engine/validator.py:122\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    120\u001b[0m     self.args.plots &= trainer.stopper.possible_stop or (trainer.epoch == trainer.epochs - 1)\n\u001b[1;32m    121\u001b[0m     model.eval()\n\u001b[0;32m--> 122\u001b[0m else:\n\u001b[1;32m    123\u001b[0m     callbacks.add_integration_callbacks(self)\n\u001b[1;32m    124\u001b[0m     model = AutoBackend(\n\u001b[1;32m    125\u001b[0m         weights=model or self.args.model,\n\u001b[1;32m    126\u001b[0m         device=select_device(self.args.device, self.args.batch),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         fp16=self.args.half,\n\u001b[1;32m    130\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:122\u001b[0m, in \u001b[0;36mAutoBackend.__init__\u001b[0;34m(self, weights, device, dnn, data, fp16, fuse, verbose)\u001b[0m\n\u001b[1;32m    107\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(weights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weights, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m weights)\n\u001b[1;32m    108\u001b[0m nn_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(weights, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    109\u001b[0m (\n\u001b[1;32m    110\u001b[0m     pt,\n\u001b[1;32m    111\u001b[0m     jit,\n\u001b[1;32m    112\u001b[0m     onnx,\n\u001b[1;32m    113\u001b[0m     xml,\n\u001b[1;32m    114\u001b[0m     engine,\n\u001b[1;32m    115\u001b[0m     coreml,\n\u001b[1;32m    116\u001b[0m     saved_model,\n\u001b[1;32m    117\u001b[0m     pb,\n\u001b[1;32m    118\u001b[0m     tflite,\n\u001b[1;32m    119\u001b[0m     edgetpu,\n\u001b[1;32m    120\u001b[0m     tfjs,\n\u001b[1;32m    121\u001b[0m     paddle,\n\u001b[0;32m--> 122\u001b[0m     ncnn,\n\u001b[1;32m    123\u001b[0m     triton,\n\u001b[1;32m    124\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_type(w)\n\u001b[1;32m    125\u001b[0m fp16 \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m pt \u001b[38;5;129;01mor\u001b[39;00m jit \u001b[38;5;129;01mor\u001b[39;00m onnx \u001b[38;5;129;01mor\u001b[39;00m xml \u001b[38;5;129;01mor\u001b[39;00m engine \u001b[38;5;129;01mor\u001b[39;00m nn_module \u001b[38;5;129;01mor\u001b[39;00m triton  \u001b[38;5;66;03m# FP16\u001b[39;00m\n\u001b[1;32m    126\u001b[0m nhwc \u001b[38;5;241m=\u001b[39m coreml \u001b[38;5;129;01mor\u001b[39;00m saved_model \u001b[38;5;129;01mor\u001b[39;00m pb \u001b[38;5;129;01mor\u001b[39;00m tflite \u001b[38;5;129;01mor\u001b[39;00m edgetpu  \u001b[38;5;66;03m# BHWC formats (vs torch BCWH)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:531\u001b[0m, in \u001b[0;36m_model_type\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    529\u001b[0m         nc = y[ib].shape[1] - y[ip].shape[3] - 4  # y = (1, 160, 160, 32), (1, 116, 8400)\n\u001b[1;32m    530\u001b[0m         self.names = {i: f\"class{i}\" for i in range(nc)}\n\u001b[0;32m--> 531\u001b[0m else:  # Lite or Edge TPU\n\u001b[1;32m    532\u001b[0m     details = self.input_details[0]\n\u001b[1;32m    533\u001b[0m     integer = details[\"dtype\"] in (np.int8, np.int16)  # is TFLite quantized int8 or int16 model\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/engine/exporter.py:71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautobackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_class_names, default_class_names\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m C2f, Detect, RTDETRDecoder\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DetectionModel, SegmentationModel, WorldModel\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     73\u001b[0m     ARM64,\n\u001b[1;32m     74\u001b[0m     DEFAULT_CFG,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     yaml_save,\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PYTHON_VERSION, check_imgsz, check_is_path_safe, check_requirements, check_version\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'WorldModel' from 'ultralytics.nn.tasks' (/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ultralytics/nn/tasks.py)"
     ]
    }
   ],
   "source": [
    "model = YOLO()\n",
    "model.train(data = \"/Users/divakar/Desktop/Yolotrain/poaching/data.yaml\", epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 69.7ms\n",
      "Speed: 7.9ms preprocess, 69.7ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 (no detections), 46.1ms\n",
      "Speed: 1.7ms preprocess, 46.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 1 weapon, 43.4ms\n",
      "Speed: 1.2ms preprocess, 43.4ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          9]\n",
      "SM8a946a8625ad26428c76338387fb1ec2\n",
      "\n",
      "0: 640x384 1 poacher, 49.8ms\n",
      "Speed: 2.1ms preprocess, 49.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 42.2ms\n",
      "Speed: 1.5ms preprocess, 42.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 46.4ms\n",
      "Speed: 1.3ms preprocess, 46.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 42.9ms\n",
      "Speed: 1.1ms preprocess, 42.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 45.0ms\n",
      "Speed: 1.2ms preprocess, 45.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 44.3ms\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 44.2ms\n",
      "Speed: 1.4ms preprocess, 44.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          9           8]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 44.1ms\n",
      "Speed: 1.2ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 44.1ms\n",
      "Speed: 1.2ms preprocess, 44.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 51.2ms\n",
      "Speed: 3.6ms preprocess, 51.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 46.0ms\n",
      "Speed: 1.4ms preprocess, 46.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 43.8ms\n",
      "Speed: 1.1ms preprocess, 43.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 45.1ms\n",
      "Speed: 1.1ms preprocess, 45.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 43.3ms\n",
      "Speed: 1.2ms preprocess, 43.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 43.1ms\n",
      "Speed: 1.3ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 (no detections), 43.3ms\n",
      "Speed: 1.3ms preprocess, 43.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 (no detections), 44.8ms\n",
      "Speed: 1.3ms preprocess, 44.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 (no detections), 44.3ms\n",
      "Speed: 1.3ms preprocess, 44.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 (no detections), 43.5ms\n",
      "Speed: 1.1ms preprocess, 43.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 (no detections), 43.4ms\n",
      "Speed: 1.3ms preprocess, 43.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 (no detections), 45.5ms\n",
      "Speed: 1.3ms preprocess, 45.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 (no detections), 44.8ms\n",
      "Speed: 1.4ms preprocess, 44.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[]\n",
      "\n",
      "0: 640x384 1 poacher, 43.6ms\n",
      "Speed: 1.1ms preprocess, 43.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 43.8ms\n",
      "Speed: 1.3ms preprocess, 43.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          9           8]\n",
      "\n",
      "0: 640x384 1 poacher, 47.4ms\n",
      "Speed: 1.2ms preprocess, 47.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 44.1ms\n",
      "Speed: 1.3ms preprocess, 44.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 43.6ms\n",
      "Speed: 1.2ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 weapon, 45.5ms\n",
      "Speed: 1.3ms preprocess, 45.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          9]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 44.7ms\n",
      "Speed: 1.2ms preprocess, 44.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 43.1ms\n",
      "Speed: 1.3ms preprocess, 43.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 61.6ms\n",
      "Speed: 1.2ms preprocess, 61.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 2 weapons, 44.8ms\n",
      "Speed: 1.1ms preprocess, 44.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          9           8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 2 weapons, 44.0ms\n",
      "Speed: 1.7ms preprocess, 44.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9           9]\n",
      "\n",
      "0: 640x384 1 poacher, 45.3ms\n",
      "Speed: 1.2ms preprocess, 45.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 45.3ms\n",
      "Speed: 1.2ms preprocess, 45.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 44.2ms\n",
      "Speed: 1.3ms preprocess, 44.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 42.1ms\n",
      "Speed: 1.4ms preprocess, 42.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 45.0ms\n",
      "Speed: 1.3ms preprocess, 45.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 1 weapon, 43.6ms\n",
      "Speed: 1.3ms preprocess, 43.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8           9]\n",
      "\n",
      "0: 640x384 1 poacher, 43.3ms\n",
      "Speed: 1.2ms preprocess, 43.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 43.3ms\n",
      "Speed: 1.3ms preprocess, 43.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 43.1ms\n",
      "Speed: 1.1ms preprocess, 43.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 48.3ms\n",
      "Speed: 1.1ms preprocess, 48.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "\n",
      "0: 640x384 1 poacher, 45.1ms\n",
      "Speed: 1.3ms preprocess, 45.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[          8]\n",
      "Error: Failed to grab a frame.\n"
     ]
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "import tensorflow\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import twilio\n",
    "from twilio.rest import Client\n",
    "import cv2\n",
    "\n",
    "\n",
    "#Defining the account_sid and auth_token provided by twilio\n",
    "account_sid = 'AC714c701c7ee80855bc13e860bfaefbd3'\n",
    "auth_token = 'c3542470a4b76b2e5f7f5f3fcdc3896d'\n",
    "\n",
    "\n",
    "#Explicitly creating a Client to send the alert message\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "\n",
    "#Defining a python function to use the created client to create and send alert\n",
    "def send_whatsapp_alert(alert_message, to):\n",
    "  global flag\n",
    "  if flag:\n",
    "     return\n",
    "  message = client.messages.create(\n",
    "    from_='whatsapp:+14155238886',\n",
    "    body=alert_message,\n",
    "    to=to\n",
    "  )\n",
    "  flag = True\n",
    "  print(message.sid)\n",
    "\n",
    "\n",
    "#Defining the alert message\n",
    "alert_message = \"❌❌Poaching activity Detected❌❌, Check the cameras immediately !!!\"\n",
    "\n",
    "\n",
    "#Defining the alert receiver's\n",
    "to = {'whatsapp:+918179533097'}\n",
    "\n",
    "\n",
    "model_path = \"/Users/divakar/Desktop/Yolotrain/poaching/runs/detect/train3/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "\n",
    "#If the input is an Image\n",
    "# from PIL import Image\n",
    "# image = Image.open(\"/Users/divakar/Desktop/Yolo train/poaching/Test Image.png\")\n",
    "\n",
    "# res = model.predict(image)\n",
    "# res = res[0]\n",
    "#     res_tensor = res.boxes.cls\n",
    "\n",
    "#     res_numpy = res_tensor.numpy()\n",
    "#     print(res_numpy)\n",
    "\n",
    "#     for i in res_numpy:\n",
    "#       if i == 9:\n",
    "#           send_whatsapp_alert(alert_message, to)\n",
    "\n",
    "flag = False\n",
    "\n",
    "\n",
    "#Read the specific video as input from local storage \n",
    "cap = cv2.VideoCapture(\"/Users/divakar/Desktop/Yolotrain/poaching/Output Video 2.mp4\")\n",
    "\n",
    "#Read the input dynamically from the connected CCTV\n",
    "#cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "count = 0\n",
    "while cap.isOpened():\n",
    "    count += 1\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "      print(\"Error: Failed to grab a frame.\")\n",
    "      break\n",
    "    if count % 30 == 0:\n",
    "      res = model.predict(frame)\n",
    "\n",
    "      res = res[0]\n",
    "      res_tensor = res.boxes.cls\n",
    "\n",
    "      res_numpy = res_tensor.numpy()\n",
    "      print(res_numpy)\n",
    "\n",
    "      for i in res_numpy:\n",
    "        if i == 9:\n",
    "            send_whatsapp_alert(alert_message, to)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/divakar/miniconda3/envs/tensorflow/bin/yolo\", line 5, in <module>\n",
      "    from yolo.script import cli\n",
      "  File \"/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/yolo/script.py\", line 20, in <module>\n",
      "    from yolo import client\n",
      "  File \"/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/yolo/client.py\", line 39, in <module>\n",
      "    import keyring\n",
      "  File \"/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keyring/__init__.py\", line 6, in <module>\n",
      "    from .core import (set_keyring, get_keyring, set_password, get_password,\n",
      "  File \"/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keyring/core.py\", line 14, in <module>\n",
      "    from . import backend\n",
      "  File \"/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keyring/backend.py\", line 18, in <module>\n",
      "    from .util import properties\n",
      "  File \"/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keyring/util/properties.py\", line 1, in <module>\n",
      "    from collections import Callable\n",
      "ImportError: cannot import name 'Callable' from 'collections' (/Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/collections/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=\"/Users/divakar/Desktop/Yolo train/poaching/runs/detect/train/weights/best.pt\" conf=0.25 source=\"/Users/divakar/Desktop/Yolo train/poaching/Output Video 2.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/Users/divakar/Desktop/Yolo train/poaching/runs/detect/train/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "cap = cv2.videoCapture(\"/Users/divakar/Desktop/Yolo train/poaching/Output Video 2.mp4\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    results = model(frame, device=\"mps\", conf=0.5)\n",
    "\n",
    "    class_names = ['-', '- annotate- and create datasets', '- collect - organize images', '- export- train- and deploy computer vision models', '- use active learning to improve your dataset over time', 'Roboflow is an end-to-end computer vision platform that helps you', 'This dataset was exported via roboflow.com on October 18- 2023 at 7-19 PM GMT', 'objectdetect - v2 2023-10-19 12-44am', 'poacher', 'weapon']\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Boxes object for bbox outputs\n",
    "        probs = result.probs  # Class probabilities for classification outputs\n",
    "        cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "        xyxy = boxes.xyxy\n",
    "        conf = boxes.conf\n",
    "        xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "        for class_index in cls:\n",
    "            class_name = class_names[int(class_index)]\n",
    "            print(\"Class:\", class_name)\n",
    "    if cv2.weightKey(15) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "for image_path in glob.glob(f\"/Users/divakar/Desktop/Yolo train/poaching/runs/detect/predict/*.jpg\")[:1]:\n",
    "    display(Image(filename=image_path, width=600))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(model.predict(\"/Users/divakar/Desktop/Yolo train/poaching/test/images/img-19_jpg.rf.175198451def55e375abab0bb0247733.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from models.yolo import Model\n",
    "from utils.general import non_max_suppression\n",
    "\n",
    "# Set the path to your YOLOv8 model.h5 file\n",
    "model_weights_path = 'poaching/runs/detect/train/weights/best.onnx'\n",
    "\n",
    "# Set the path to your single test image\n",
    "image_path = 'poaching/train/images/img-10_jpg.rf.e505d13e037c596061c34e876a6f228c.jpg'\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = Model(weights=model_weights_path)\n",
    "\n",
    "# Set device (cuda if available, else cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Read the single test image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform inference\n",
    "results = model(image)\n",
    "\n",
    "# Apply non-maximum suppression to remove redundant bounding boxes\n",
    "results = non_max_suppression(results, conf_thres=0.5, iou_thres=0.4)\n",
    "\n",
    "# Draw bounding boxes on the image\n",
    "if results[0] is not None:\n",
    "    for box in results[0]:\n",
    "        x, y, w, h = box[:4]\n",
    "        label = int(box[5])\n",
    "        confidence = box[4]\n",
    "\n",
    "        # Draw bounding box and label on the image\n",
    "        cv2.rectangle(image, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"Class {label} - {confidence:.2f}\", (int(x), int(y) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('YOLOv8 Inference', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twilio\n",
      "  Downloading twilio-8.12.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from twilio) (2.31.0)\n",
      "Collecting PyJWT<3.0.0,>=2.0.0 (from twilio)\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting aiohttp>=3.8.4 (from twilio)\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting aiohttp-retry>=2.8.3 (from twilio)\n",
      "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp>=3.8.4->twilio)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from aiohttp>=3.8.4->twilio) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.8.4->twilio)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.8.4->twilio)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.8.4->twilio)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp>=3.8.4->twilio)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.0.0->twilio) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.0.0->twilio) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.0.0->twilio) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divakar/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.0.0->twilio) (2023.11.17)\n",
      "Downloading twilio-8.12.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp310-cp310-macosx_11_0_arm64.whl (387 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.4/387.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyJWT, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, aiohttp-retry, twilio\n",
      "Successfully installed PyJWT-2.8.0 aiohttp-3.9.3 aiohttp-retry-2.8.3 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 multidict-6.0.5 twilio-8.12.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This if the code for alert creation.\n",
    "from twilio.rest import Client\n",
    "\n",
    "account_sid='AC714c701c7ee80855bc13e860bfaefbd3'\n",
    "auth_token = 'c3542470a4b76b2e5f7f5f3fcdc3896d'\n",
    "twilio_phone_number = 'whatsapp:+14157636913'\n",
    "recipient_phone_numbers = ['whatsapp:+918179533097']\n",
    "\n",
    "# Create a Twilio client\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "def send_whatsapp_message(message_content,to):\n",
    "    # Send the message\n",
    "    message = client.messages.create(\n",
    "        body=message_content,\n",
    "        from_=twilio_phone_number,\n",
    "        to=to\n",
    "    )\n",
    "\n",
    "    # Print the message SID (optional)\n",
    "    print(f\"Message SID: {message.sid}\")\n",
    "\n",
    "event_message_content = \"Poaching Activity Detected. Check the Camera's !!!\"\n",
    "message_sent = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMb870be13d2acf16f3352c41abfd6fd6d\n"
     ]
    }
   ],
   "source": [
    "from twilio.rest import Client\n",
    "\n",
    "account_sid = 'AC714c701c7ee80855bc13e860bfaefbd3'\n",
    "auth_token = 'c3542470a4b76b2e5f7f5f3fcdc3896d'\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "def send_whatsapp_alert(alert_message, to):\n",
    "  message = client.messages.create(\n",
    "    from_='whatsapp:+14155238886',\n",
    "    body=alert_message,\n",
    "    to=to\n",
    "  )\n",
    "\n",
    "  print(message.sid)\n",
    "\n",
    "alert_message = \"Poaching activity Detected ❌❌❌, Check the cameras immediately !!!\"\n",
    "to = 'whatsapp:+918179533097'\n",
    "\n",
    "\n",
    "#send_whatsapp_alert(alert_message, to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 22\u001b[0m\n\u001b[1;32m     16\u001b[0m     server\u001b[38;5;241m.\u001b[39mquit()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Subject = \"ALERT !!!\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Body = \"Poaching activity detected, do check camera footage immediately !\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# To = \"divakarmikkilineni123@gmail.com\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[43memail_alert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALERT !!!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPoaching activity detected, do check camera footage immediately !\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdivakarmikkilineni123@gmail.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 12\u001b[0m, in \u001b[0;36memail_alert\u001b[0;34m(subject, body, to)\u001b[0m\n\u001b[1;32m      9\u001b[0m msg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m user\n\u001b[1;32m     10\u001b[0m password \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgmail3927\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m server \u001b[38;5;241m=\u001b[39m \u001b[43msmtplib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSMTP\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msmtp.gmail.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m server\u001b[38;5;241m.\u001b[39mstarttls()\n\u001b[1;32m     14\u001b[0m server\u001b[38;5;241m.\u001b[39mlogin(user, password)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/smtplib.py:255\u001b[0m, in \u001b[0;36mSMTP.__init__\u001b[0;34m(self, host, port, local_hostname, timeout, source_address)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_challenge_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m host:\n\u001b[0;32m--> 255\u001b[0m     (code, msg) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m220\u001b[39m:\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/smtplib.py:341\u001b[0m, in \u001b[0;36mSMTP.connect\u001b[0;34m(self, host, port, source_address)\u001b[0m\n\u001b[1;32m    339\u001b[0m     port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_port\n\u001b[1;32m    340\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmtplib.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, host, port)\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    343\u001b[0m (code, msg) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetreply()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/smtplib.py:312\u001b[0m, in \u001b[0;36mSMTP._get_socket\u001b[0;34m(self, host, port, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebuglevel \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_debug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnect: to\u001b[39m\u001b[38;5;124m'\u001b[39m, (host, port), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address)\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/socket.py:833\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    832\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 833\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    835\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Trigger function that activates the alert if GUN is detected.\n",
    "def email_alert(subject, body, to):\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(body)\n",
    "    msg['subject'] = subject\n",
    "    msg['to'] = to\n",
    "\n",
    "    user = \"divakarmikkilineni123@gmail.com\"\n",
    "    msg['from'] = user\n",
    "    password = \"gmail3927\"\n",
    "\n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\")\n",
    "    server.starttls()\n",
    "    server.login(user, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Subject = \"ALERT !!!\"\n",
    "    # Body = \"Poaching activity detected, do check camera footage immediately !\"\n",
    "    # To = \"divakarmikkilineni123@gmail.com\"\n",
    "    email_alert(\"ALERT !!!\", \"Poaching activity detected, do check camera footage immediately !\", \"divakarmikkilineni123@gmail.com\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"/Users/divakar/Desktop/Yolo train/poaching/Test Image.png\")\n",
    "\n",
    "res = model.predict(image)\n",
    "res = res[0]\n",
    "    res_tensor = res.boxes.cls\n",
    "\n",
    "    res_numpy = res_tensor.numpy()\n",
    "    print(res_numpy)\n",
    "\n",
    "    for i in res_numpy:\n",
    "      if i == 9:\n",
    "          send_whatsapp_alert(alert_message, to)\n",
    "\n",
    "\n",
    "          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
